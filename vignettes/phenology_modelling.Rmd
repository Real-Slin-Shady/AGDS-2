---
title: "Phenology Modelling"
author: "Nils Tinner"
date: "`r Sys.Date()`"
output: html_document
---

Ways to improve spatial scaling of model:
1) Respect plant species
2) Choose data from local site
3) Use more parameters for model

--> 3 one is chosen
```{r}
phenocamr::download_phenocam(
  site = "harvard$",
  veg_type = "DB",
  roi_id = "1000",
  daymet = TRUE,
  phenophase = TRUE,
  trim = 2022,
  out_dir = tempdir()
)

harvard_phenocam_data <- readr::read_csv(
  file.path(tempdir(), "harvard_DB_1000_3day.csv"),
  comment = "#"
)

# reading in harvard phenology only retaining
# spring (rising) phenology for the GCC 90th
# percentile time series (the default)
harvard_phenology <- readr::read_csv(
  file.path(
    tempdir(),
    "harvard_DB_1000_3day_transition_dates.csv"
  ),
  comment = "#"
) |>
  dplyr::filter(
    direction == "rising",
    gcc_value == "gcc_90"
  )


```
Now also respect solar radiation

```{r}
harvard_temp <- harvard_phenocam_data |>
  group_by(year) |>
  dplyr::mutate(
    tmean = (tmax..deg.c. + tmin..deg.c.)/2
  ) |>
  dplyr::mutate(
    date = as.Date(date),
    gdd = cumsum(ifelse(tmean >= 5, tmean - 5, 0))
  ) |>
  dplyr::select(
    date,
    year,
    tmean,
    gdd,
    srad..W.m.2.
  ) |>
  dplyr::ungroup()

```

```{r}
harvard_phenology <- harvard_phenology |>
  mutate(
    doy = as.numeric(format(as.Date(transition_25),"%j")),
    year = as.numeric(format(as.Date(transition_25),"%Y"))
  ) |>
  select(
    year,
    doy,
    transition_25,
    threshold_25
  )


```


```{r}
gdd_model <- function(data_met, par) {
  # split out parameters from a simple
  # vector of parameter values
  temp_threshold <- par[1]
  gdd_crit <- par[2]
  solar_impact <- par[3]

  # accumulate growing degree days for
  # temperature data
  temp <- data_met[seq(from = 1, to = length(data_met)/2,by = 1)]
  sol <- data_met[seq(from = length(data_met)/2+1, to = length(data_met),by = 1)]



  gdd <- cumsum(ifelse(temp > temp_threshold, temp - temp_threshold, 0))
  gdd <- gdd + (sol-mean(sol))/sd(sol)*solar_impact
  # figure out when the number of growing
  # degree days exceeds the minimum value

  # required for leaf development, only
  # return the first value
  doy <- unlist(which(gdd >= gdd_crit)[1])

  return(doy)
}

```

```{r}
rmse_gdd <- function(par, data) {

  # split out data
  drivers <- data$drivers
  validation <- data$validation

  # calculate phenology predictions
  # and put in a data frame
  predictions <- drivers |>
    group_by(year) |>
    summarise(
      predictions = gdd_model(
        data_met = c(tmean,srad..W.m.2.),
        par = par
      )
    )

  predictions <- left_join(predictions, validation, by = "year")

  rmse <- predictions |>
    summarise(
      rmse = sqrt(mean((predictions - doy)^2, na.rm = TRUE))
    ) |>
    pull(rmse)

  # return rmse value
  return(rmse)
}
```


```{r}
# starting model parameters
par = c(0, 130,1)

# limits to the parameter space
lower <- c(-10,0,0.000001)
upper <- c(45,500,10000)

# data needs to be provided in a consistent
# single data file, a nested data structure
# will therefore accept non standard data formats
data <- list(
  drivers = harvard_temp,
  validation = harvard_phenology
)

# optimize the model parameters
optim_par = GenSA::GenSA(
  par = par,
  fn = rmse_gdd,
  lower = lower,
  upper = upper,
  control = list(
    max.call = 4000
  ),
  data = data
)$par



```



```{r}

predictions <- harvard_temp |>
  group_by(year) |>
  summarize(
    prediction = gdd_model(
      data_met = c(tmean,srad..W.m.2.),
      par = optim_par
    )
  )


# join predicted with observed data
validation <- left_join(predictions, harvard_phenology)

ggplot2::ggplot(validation) +
  geom_smooth(
    aes(
      doy,
      prediction
    ),
    colour = "grey25",
    method = "lm"
  ) +
  geom_point(
    aes(
      doy,
      prediction
    )
  ) +
  geom_abline(
    intercept=0,
    slope=1,
    linetype="dotted"
  ) +
  labs(
    x = "Observed leaf-out date (DOY)",
    y = "Predicted leaf-out date (DOY)"
  ) +
  theme_bw()  +
  theme(
    legend.position = "none"
  )

```



```{r}
library(daymetr)

# # Download daily data
# daymetr::download_daymet_tiles(
#   tiles = 11935,
#   start = 2012,
#   end = 2012,
#   param = c("tmin","tmax","srad"),
#   path = paste0(here::here(), "/data-raw/"),
#   silent = TRUE
#   )

# calculate the daily mean values
r <- daymetr::daymet_grid_tmean(
  path = paste0(here::here(), "/data-raw/"),
  product = 11935,
  year = 2012,
  internal = TRUE
)
r_2 <- terra::rast(paste0(here::here(), "/data-raw/","srad_2012_11935.nc"))



# reproject to lat lon
r <- terra::project(
  r,
  "+init=epsg:4326"
)


# subset to first 180 days
ma_nh_temp <- terra::subset(
  r,
  1:180
)

# reproject to lat lon
r_2 <- terra::project(
  r_2,
  "+init=epsg:4326"
)


# subset to first 180 days
ma_nh_sol <- terra::subset(
  r_2,
  1:180
)
```

```{r}


predicted_phenology <- terra::app(
  c(ma_nh_temp,ma_nh_sol),
  fun = gdd_model,
  par = optim_par
)


```



```{r}

library(leaflet)
library(terra)

# set te colour scale manually
pal <- colorNumeric(
  "magma",
  values(predicted_phenology),
  na.color = "transparent"
)

# build the leaflet map
# using ESRI tile servers
# and the loaded demo raster
leaflet() |>
  addProviderTiles(providers$Esri.WorldImagery, group = "World Imagery") |>
  addProviderTiles(providers$Esri.WorldTopoMap, group = "World Topo") |>
  addRasterImage(
    predicted_phenology,
    colors = pal,
    opacity = 0.8,
    group = "Phenology model results"
  ) |>
  addLayersControl(
    baseGroups = c("World Imagery","World Topo"),
    position = "topleft",
    options = layersControlOptions(collapsed = FALSE),
    overlayGroups = c("Phenology model results")
  ) |>
  addLegend(
    pal = pal,
    values = terra::values(predicted_phenology),
    title = "DOY")

```
