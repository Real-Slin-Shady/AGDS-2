---
title: "Phenology Modelling"
author: "Nils Tinner"
date: "`r Sys.Date()`"
output: html_document
---

This excercise builds upon the model presented in "https://geco-bern.github.io/handfull_of_pixels/phenology_modelling.html". The first task is to think of ways to improve the model. The following are ideas that I came up with.

1) Add more training data
2) Add information about plant species
3) Use more parameters for model

This markdown implements adding more data and using an additional parameter.

First, the same workflow for harvard data download is performed as in the turorial. This is also done for an additional site: Bartel.

```{r, echo=FALSE}
packages <- c("phenocamr","dplyr","ggplot2","lubridate","daymetr","leaflet","terra","MODISTools","daymetr") 

source("../R/load_packages.R")
load_packages(packages)#loading packages

phenocamr::download_phenocam(
  site = "harvard$",
  veg_type = "DB",
  roi_id = "1000",
  daymet = TRUE,
  phenophase = TRUE,
  trim = 2022,
  out_dir = tempdir()
) #Downloading phenocam data

harvard_phenocam_data <- readr::read_csv(
  file.path(tempdir(), "harvard_DB_1000_3day.csv"),
  comment = "#"
) #phenocam data read in

# reading in harvard phenology only retaining
# spring (rising) phenology for the GCC 90th
# percentile time series (the default)
harvard_phenology <- readr::read_csv(
  file.path(
    tempdir(),
    "harvard_DB_1000_3day_transition_dates.csv"
  ),
  comment = "#"
) |>
  dplyr::filter(
    direction == "rising",
    gcc_value == "gcc_90"
  )

#Now we also load data from the bartlettir site. same as for harvard
phenocamr::download_phenocam(
  site = "bartlettir$",
  veg_type = "DB",
  roi_id = "1000",
  daymet = TRUE,
  phenophase = TRUE,
  trim = 2022,
  out_dir = tempdir()
)

bartel_phenocam_data <- readr::read_csv(
  file.path(tempdir(), "bartlettir_DB_1000_3day.csv"),
  comment = "#"
)

#we apply the same processing
bartel_phenology <- readr::read_csv(
  file.path(
    tempdir(),
    "bartlettir_DB_1000_3day_transition_dates.csv"
  ),
  comment = "#"
) |>
  dplyr::filter(
    direction == "rising",
    gcc_value == "gcc_90"
  )

```
Then gdd, tmean and rad are extracted for each date and site. This is the same as in the tutorial just now also with radiation and for both sites. Afterwards we combine both dataframes.

```{r, echo=FALSE}
#harvard temp and also radiation since used to improve model
harvard_temp <- harvard_phenocam_data |>
  group_by(year) |>
  dplyr::mutate(
    tmean = (tmax..deg.c. + tmin..deg.c.)/2
  ) |>
  dplyr::mutate(
    date = as.Date(date),
    gdd = cumsum(ifelse(tmean >= 5, tmean - 5, 0))
  ) |>
  dplyr::select(
    date,
    year,
    tmean,
    gdd,
    srad..W.m.2. #Now we added also solar radiation
  ) |>
  dplyr::ungroup()|>
  mutate(site = "Harvard") #we give a name to be able to identify the sites later on

#we do the same for bartel-site
bartel_temp <- bartel_phenocam_data |>
  group_by(year) |>
  dplyr::mutate(
    tmean = (tmax..deg.c. + tmin..deg.c.)/2
  ) |>
  dplyr::mutate(
    date = as.Date(date),
    gdd = cumsum(ifelse(tmean >= 5, tmean - 5, 0))
  ) |>
  dplyr::select(
    date,
    year,
    tmean,
    gdd,
    srad..W.m.2.
  ) |>
  dplyr::ungroup()|>
    mutate(site = "Bartel")
all_temp <- rbind(bartel_temp,harvard_temp) #then we combine the dataset

```
Now we process the phenology data as in the tutorial but for both sites. Afterwards we combine both dataframes.
```{r, echo=FALSE}
#for Harvard
harvard_phenology <- harvard_phenology |>
  mutate(
    doy = as.numeric(format(as.Date(transition_25),"%j")),
    year = as.numeric(format(as.Date(transition_25),"%Y"))
  ) |>
  select(
    year,
    doy,
    transition_25,
    threshold_25
  )|>
    mutate(site = "Harvard")
#same for bartel
bartel_phenology <- bartel_phenology |>
  mutate(
    doy = as.numeric(format(as.Date(transition_25),"%j")),
    year = as.numeric(format(as.Date(transition_25),"%Y"))
  ) |>
  select(
    year,
    doy,
    transition_25,
    threshold_25
  )|>
    mutate(site = "Bartel")


all_pheno <- rbind(bartel_phenology,harvard_phenology) #again we combine

```

Now, the function is also changed, so that the radiation also has an impact. The radiation is z standardized and then added to the value of gdd. To perform a spatial upscaling later, the two parameters need to be passed as a list. Other than that, the function corresponds to the one used in the exercise.

```{r}
gdd_model <- function(data_met, par) {
  # split out parameters from a simple
  # vector of parameter values
  temp_threshold <- par[1]
  gdd_crit <- par[2]
  solar_impact <- par[3]

  #taking apart the meteodata fed to the model
  temp <- data_met[seq(from = 1, to = length(data_met)/2,by = 1)]
  sol <- data_met[seq(from = length(data_met)/2+1, to = length(data_met),by = 1)]


  #using temp for growing degree days
  gdd <- cumsum(ifelse(temp > temp_threshold, temp - temp_threshold, 0))
  gdd <- gdd + (sol-mean(sol))/sd(sol)*solar_impact #A z standardized impact of the precipitation on gdd...



  doy <- unlist(which(gdd >= gdd_crit)[1]) #doy

  return(doy)
}

```
The rmse function is then the same as in the exercise. Only now we also have the site id.

```{r}
rmse_gdd <- function(par, data) {

  # split out data
  drivers <- data$drivers
  validation <- data$validation



  # calculate phenology predictions
  # and put in a data frame
  predictions <- drivers |>
    group_by(year,site) |> #now also sites
    summarise(
      predictions = gdd_model(
        data_met = c(tmean,srad..W.m.2.),#temp and solar rad
        par = par
      ),
      .groups = 'drop'
    )|>
    ungroup()

  predictions <- left_join(predictions, validation, by = c("year","site"))

  rmse <- predictions |>
    summarise(
      rmse = sqrt(mean((predictions - doy)^2, na.rm = TRUE))
    ) |>
    pull(rmse)

  # return rmse value
  return(rmse)
}
```

Now we tune the model. For. this parameters are set as following:

```{r}
# starting model parameters
par = c(0, 130,1) 

# limits to the parameter space
lower <- c(-10,0,0.000001)
upper <- c(45,500,10000)

# data needs to be provided in a consistent
# single data file, a nested data structure
# will therefore accept non standard data formats
data <- list(
  drivers = all_temp,
  validation = all_pheno
)

# optimize the model parameters
optim_par = GenSA::GenSA(
  par = par,
  fn = rmse_gdd,
  lower = lower,
  upper = upper,
  control = list(
    max.call = 4000
  ),
  data = data
)$par



```

Now we plot the model performence

```{r, echo=FALSE}
#make predictions
predictions <- all_temp |>
  group_by(year,site) |>
  summarize(
    prediction = gdd_model(
      data_met = c(tmean,srad..W.m.2.),
      par = optim_par
    )
  )


# join predicted with observed data
validation <- left_join(predictions, all_pheno) |>tidyr::drop_na()
#plot with respect to sites
# Calculate R-squared and RMSE
rsq <- cor(validation$prediction, validation$doy)^2
rmse <- sqrt(mean((validation$prediction - validation$doy)^2))

# Create the plot
ggplot(validation) +
  geom_smooth(
    aes(
      doy,
      prediction,
    ),
    colour = "grey25",
    method = "lm"
  ) +
  geom_point(
    aes(
      doy,
      prediction,
      col = site
    )
  ) +
  geom_abline(
    intercept=0,
    slope=1,
    linetype="dotted"
  ) +
  labs(
    x = "Observed leaf-out date (DOY)",
    y = "Predicted leaf-out date (DOY)"
  ) +
  theme_bw() +
  annotate(
    "text",
    x = min(validation$doy) + 5,
    y = max(validation$prediction) + 1,
    label = paste0("R-squared = ", round(rsq, 3)),
  ) +
  annotate(
    "text",
    x = min(validation$doy) + 5,
    y = max(validation$prediction) ,
    label = paste0("RMSE = ", round(rmse, 3)),
  )


```

Now, we rast the daymet data for spatial upscaling and laster statistical comparison. We also perform a assignment of coordinate system we only look at the first 180 days. For both radiation and mean temperature. But for now just the year 2012.

```{r}


# Download daily data, this may take a wile, other data is used later
daymetr::download_daymet_tiles(
  tiles = 11935,
  start = 2008,
  end = 2012,
  param = c("tmin","tmax","srad"),
  path = paste0(here::here(), "/data-raw/"),
  silent = TRUE
  )

# calculate the daily mean values
r <- daymetr::daymet_grid_tmean(
  path = paste0(here::here(), "/data-raw/"),
  product = 11935,
  year = 2012,
  internal = TRUE
)#temperature

r_2 <- terra::rast(paste0(here::here(), "/data-raw/","srad_2012_11935.nc")) #radiation



# reproject to lat lon
r <- terra::project(
  r,
  "+init=epsg:4326"
)


# subset to first 180 days
ma_nh_temp <- terra::subset(
  r,
  1:180
)

# reproject to lat lon also for rad
r_2 <- terra::project(
  r_2,
  "+init=epsg:4326"
)


# subset to first 180 days
ma_nh_sol <- terra::subset(
  r_2,
  1:180
)
```

Now we spatially upscale.

```{r}


predicted_phenology <- terra::app(
  c(ma_nh_temp,ma_nh_sol),
  fun = gdd_model,
  par = optim_par
)


```

First, a nice overview of the model predictions.

```{r, echo=FALSE}



# set te colour scale manually
pal <- colorNumeric(
  "magma",
  values(predicted_phenology),
  na.color = "transparent"
)

# build the leaflet map
# using ESRI tile servers
# and the loaded demo raster
leaflet() |>
  addProviderTiles(providers$Esri.WorldImagery, group = "World Imagery") |>
  addProviderTiles(providers$Esri.WorldTopoMap, group = "World Topo") |>
  addRasterImage(
    predicted_phenology,
    colors = pal,
    opacity = 0.8,
    group = "Phenology model results"
  ) |>
  addLayersControl(
    baseGroups = c("World Imagery","World Topo"),
    position = "topleft",
    options = layersControlOptions(collapsed = FALSE),
    overlayGroups = c("Phenology model results")
  ) |>
  addLegend(
    pal = pal,
    values = terra::values(predicted_phenology),
    title = "DOY")

```

Now we visually compare the modis data to our model. We also need to crop the modis and our data to the same extend.
```{r, echo=FALSE}



# download and save phenology data
phenology <- MODISTools::mt_subset(
  product = "MCD12Q2",
  lat = 43.152662,
  lon =  -71.382337,
  band = "Greenup.Num_Modes_01",
  start = "2012-01-01",
  end = "2012-12-31",
  km_lr = 50,
  km_ab = 50,
  internal = TRUE,
  progress = TRUE
)

phenology <- phenology |>
  mutate(
    value = as.numeric(format(as.Date("1970-01-01") + value, "%j")),#mutate dates...
    value = ifelse (value < 200, value, NA)) #data quality control
#now raster
phenology_raster <- MODISTools::mt_to_terra(
  phenology,
  reproject = TRUE
)

#now processing: cropping to each others extend...
predicted_phenology <- terra::crop(
  x = predicted_phenology,
  y = phenology_raster
)

phenology_raster <- terra::crop(
  x = phenology_raster,
  y = predicted_phenology
)

#and adjusting resolution
phenology_raster <- terra::resample(
  x = phenology_raster,
  y = predicted_phenology,
  method = "average"
)

predicted_phenology <- terra::mask(
  predicted_phenology,
  is.na(phenology_raster),
  maskvalues = TRUE
)

 ggplot() +
  tidyterra::geom_spatraster(data = phenology_raster) +
  scale_fill_viridis_c(
    na.value = NA,
    name = "DOY"
    ) +
  theme_bw()
 
  ggplot() +
  tidyterra::geom_spatraster(data = predicted_phenology) +
  scale_fill_viridis_c(
    na.value = NA,
    name = "DOY"
    ) +
  theme_bw()
 
#resulting in these two maps:
```
 Interesting. We see almost no visible correlation. Lets check this:
 We perform a correlation for each pixel of the map of the modis data to our predicted data.
  
```{r, echo=FALSE}
  
  #Now we compare for the year 2012
  predicted_df <- as.vector(predicted_phenology)
phenology_df <- as.vector(phenology_raster)
sct_df <- data.frame(
  doy_p = predicted_df,
  doy_m = phenology_df
  )|>
  tidyr::drop_na()

ggplot(
  data = sct_df,
      aes(
      doy_p,
      doy_m
    )
  ) +
  geom_point() +
  scale_fill_viridis_c(trans="log10") +
  geom_smooth(
    method = "lm",
    se = FALSE,
    colour = "black",
    lty = 2
  ) +
  labs(
    x = "predicted maturity (DOY)",
    y = "MODIS vegetation maturity (DOY)"
  ) +
  annotate("text",x = 110, y = 145, label = paste("R-squared:", round(cor(sct_df$doy_p,sct_df$doy_m)^2, 3))) +
  annotate("text",x = 110, y = 150, label = paste("RMSE:", round(sqrt(mean((sct_df$doy_p - sct_df$doy_m)^2)), 3)))+
  theme_bw()
```
Not looking very promising, a very waek correlation if at all. Lets generalize this to the years 2008-2012
```{r, echo=FALSE}
sct_df <- data.frame(
  doy_p = NULL,
  doy_m = NULL,
  year = NULL
  )
for (temp_year in c(2008:2012)) {

# calculate the daily mean values
r <- daymetr::daymet_grid_tmean(
  path = paste0(here::here(), "/data-raw/"),
  product = 11935,
  year = temp_year,
  internal = TRUE
)
r_2 <- terra::rast(paste0(here::here(), "/data-raw/","srad_",temp_year,"_11935.nc"))



# reproject to lat lon
r <- terra::project(
  r,
  "+init=epsg:4326"
)


# subset to first 180 days
ma_nh_temp <- terra::subset(
  r,
  1:180
)

# reproject to lat lon
r_2 <- terra::project(
  r_2,
  "+init=epsg:4326"
)


# subset to first 180 days
ma_nh_sol <- terra::subset(
  r_2,
  1:180
)



predicted_phenology <- terra::app(
  c(ma_nh_temp,ma_nh_sol),
  fun = gdd_model,
  par = optim_par
)
# download and save phenology data
phenology <- MODISTools::mt_subset(
  product = "MCD12Q2",
  lat = 43.152662,
  lon =  -71.382337,
  band = "Greenup.Num_Modes_01",
  start = paste0(temp_year,"-01-01"),
  end = paste0(temp_year,"-12-31"),
  km_lr = 50,
  km_ab = 50,
  internal = TRUE,
  progress = TRUE
)

phenology <- phenology |>
  mutate(
    value = as.numeric(format(as.Date("1970-01-01") + value, "%j")),
    value = ifelse (value < 200, value, NA))

phenology_raster <- MODISTools::mt_to_terra(
  phenology,
  reproject = TRUE
)


predicted_phenology <- terra::crop(
  x = predicted_phenology,
  y = phenology_raster
)

phenology_raster <- terra::crop(
  x = phenology_raster,
  y = predicted_phenology
)


phenology_raster <- terra::resample(
  x = phenology_raster,
  y = predicted_phenology,
  method = "average"
)

predicted_phenology <- terra::mask(
  predicted_phenology,
  is.na(phenology_raster),
  maskvalues = TRUE
)
print(str(data.frame(
  doy_p = predicted_df,
  doy_m = phenology_df,
  year = temp_year
  )))

 predicted_df <- as.vector(predicted_phenology)
phenology_df <- as.vector(phenology_raster)
sct_df <- rbind(sct_df,data.frame(
  doy_p = predicted_df,
  doy_m = phenology_df,
  year = temp_year
  ))

}



sct_df <- sct_df |>
  tidyr::drop_na()




ggplot(
  data = sct_df,
      aes(
      doy_p,
      doy_m,
      col = year
    )
  ) +
  geom_point() +
  scale_fill_viridis_c(trans="log10") +
  geom_smooth(
    method = "lm",
    se = FALSE,
    colour = "white",
    lty = 2
  ) +
  labs(
    x = "predicted maturity (DOY)",
    y = "MODIS vegetation maturity (DOY)"
  ) +
  annotate("text",x = 110, y = 145, label = paste("R-squared:", round(cor(sct_df$doy_p,sct_df$doy_m)^2, 3))) +
  annotate("text",x = 110, y = 150, label = paste("RMSE:", round(sqrt(mean((sct_df$doy_p - sct_df$doy_m)^2)), 3)))+
  theme_bw()


```
Alright, looks much better. Still the RMSE remains very high. I expect that mainly the yearly signal correlates and the spatial still does not.
